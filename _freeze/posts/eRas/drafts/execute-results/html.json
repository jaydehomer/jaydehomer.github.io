{
  "hash": "361813e15c2e163a7880c7f6102444fe",
  "result": {
    "markdown": "---\nexecute:\n  eval: false\n---\n\n\n\n## Plays \n\n\n\n\nOne very important piece of information that we are not allowed to access from Spotify, for some unknown but infuriating nonetheless reason, is playback or number of streams. We can get it for our own account (maybe I'll do that another time), but not for all users ever. But....\n\nIt's hard to fight when th–µ fight ain't fair\nWe're getting stronger now, find things they never found\nThey might be bigger but we're faster and never scared\n\nSo, yes, we can get streaming info. It's just a bit of an adventure into Wonderland! I found and subscribed to a potentially-sketchy web API... https://rapidapi.com/developer/dashboard\n\nNow, I can pull streaming/playback info (caveat, only for 20 songs per day). So, this project will take a while to complete for streaming info. Unless Spotify allows us to pull streaming info for songs some time soon, which is doubtful, I'll keep using this API I'm now subscribed to.\n\nThe following code queries the database (tbd on when that playback info is backdated?) using the track_id. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# queryString <- list(spotify_track_id = \"XXXXXXXXXX\")\n# \n# response <- VERB(\"GET\", \n#                  url, \n#                  query = queryString, \n#                  add_headers('X-RapidAPI-Key' = '19547ae2bdmsh4d5cd37c8c39d7fp1a033bjsnaa6639064938', \n#                              'X-RapidAPI-Host' = 'spotify-track-streams-playback-count1.p.rapidapi.com'),\n#                  content_type(\"application/octet-stream\"))\n```\n:::\n\n\ntest for Lavender Haze\n\ntrack id = 24emu3sabKISjRkrys28jq\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# queryString <- list(spotify_track_id = \"24emu3sabKISjRkrys28jq\")\n# \n# # response <- VERB(\"GET\", \n# #                  url, \n# #                  query = queryString, \n# #                  add_headers('X-RapidAPI-Key' = '19547ae2bdmsh4d5cd37c8c39d7fp1a033bjsnaa6639064938', \n# #                              'X-RapidAPI-Host' = 'spotify-track-streams-playback-count1.p.rapidapi.com'),\n# #                  content_type(\"application/octet-stream\"))\n# \n# content(response, \"text\")\n```\n:::\n\n\nWhich results in a text list containing (among other things) the track_id and stream number, which we can add to our file somewhat manually, like so: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# track_plays[4, 3] <- content(response)[4][[1]]\n# track_plays[4, 4] <- date()\n```\n:::\n\n\nOf course I'd prefer not to do that for 465 songs, so let's loop that shit. \n\nFirst, we want to set up a subset for N tracks that we want to get playback info for, so we don't break the bank ($.50 per additional API call after 20... that's more money than I have in my bank account!!!). Then we send that subset into the loop, get playback info for the track, add plaayback info and the date it was accessed to our track_plays file, rinse and repeat. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# url <- \"https://spotify-track-streams-playback-count1.p.rapidapi.com/tracks/spotify_track_streams\"\n# \n# no_plays <- track_plays |> \n#   filter(is.na(plays)) |> \n#   head(6)\n# \n# for(t in 1:nrow(no_plays)){\n#   track <- no_plays[t, 1]\n#   queryString <- list(spotify_track_id = track$track_id)\n#   response <- VERB(\"GET\",\n#                    url,\n#                    query = queryString,\n#                    add_headers('X-RapidAPI-Key' = '19547ae2bdmsh4d5cd37c8c39d7fp1a033bjsnaa6639064938',\n#                                'X-RapidAPI-Host' = 'spotify-track-streams-playback-count1.p.rapidapi.com'),\n#                    content_type(\"application/octet-stream\"))\n#   track_plays[which(track_plays$track_id==track$track_id), 3] <- content(response)[4][[1]]\n#   track_plays[which(track_plays$track_id==track$track_id), 4] <- date()\n# }\n\n# in case need to do a manual entry \n#track_plays[which(track_plays$track_id==\"0GKDhq6ZbmSbRHd3eyGlB7\"), 3] <- 229475778\n```\n:::\n\n\nI then write this file out to a csv to store it after each day's API access is maxed so I can read it in and add more data the next day (so long as I remember to do so). At this rate, it will take probably a month (if I am diligent and make minimal errors) to get all of the stream data in. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrack_plays\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(track_plays, \"track_plays.csv\")\n```\n:::\n\n\nTo bring it all full circle, we can also add track_plays to the swifty data!!!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nswifty <- left_join(swifty, track_plays, by = c(\"track_name\", \"track_id\"))\nglimpse(swifty)\n```\n:::\n\n\n------------\n\nReferences: \n\nhttps://shaynak.github.io/taylor-swift/ -- while I'm pretty confident in my brain's ability to store endless lyrics, this website made possible all of the lyrics and references found throughout this project\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}